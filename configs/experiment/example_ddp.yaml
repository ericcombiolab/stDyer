# @package _global_

# to execute this experiment run:
# python run.py experiment=example_ddp

defaults:
  - override /mode: exp.yaml
  - override /trainer: stdyer.yaml
  - override /model: dgg.yaml
  - override /datamodule: dgg.yaml
  - override /callbacks: stdyer.yaml
  - override /logger: none.yaml

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

# name of the run determines folder name in logs
# can also be accessed by loggers
name: "example_ddp"
model:
  lr: 0.001

  # learning rate for Gaussian uniform prior, set to 0 will use uniform prior all the time
  prior_lr: 0.2

  gaussian_size: 64
  attention_size: 64

  exp_encoder_channels: [3000, 128, 256, 64]
  exp_decoder_channels: [64, 256, 128, 3000]

  # weight for neighbor loss, higher weights will make the predicted domains smoother
  exp_neigh_w: 1.

  # starting from this epoch to use fused graph
  patience_start_epoch_pct: 50
  # starting from this epoch to use Gaussian loss
  gaussian_start_epoch_pct: 50
  # parameter of semi-supervised cross-entropy loss
  # higher weights can make the model stick to the domain labels initialized by mclust
  # lower weights can make the model more flexible to update the domain labels
  # you can set it with either "1.001" or "1.01" for testing
  semi_ce_degree: "1.01"

trainer:
  # number of epochs to train
  max_epochs: 100
  # number of GPUs to use (require set datamodule.use_ddp to True at the bottom of this config file)
  devices: 2

datamodule:
  # full path to the dataset: data_dir/dataset_dir/sample_id.h5ad
  data_dir: "/home/comp/20481195/Datasets/Stereo-seq"
  dataset_dir: "MOSTA"
  sample_id: "E16.5_E2S7.MOSTA"
  # specify data_type as "custom" and use data_file_name for your own dataset
  # data_file_name: "E16.5_E2S7.MOSTA.h5ad"
  data_type: "bgi" # "custom"

  # number of predicted spatial domains
  num_classes: 7
  # number of highly variable genes
  num_hvg: 3000

  # a: number of fixed spatial units to use
  unit_fix_num: 4
  # b: number of dynamic domain units to use
  unit_dynamic_num: 4
  k: 8 # a+b
  rec_neigh_num: 8 # a+b
  forward_neigh_num: 8 # a+b
  max_dynamic_neigh: 8 # a+b

  # use all highly variable genes and perform z-score normalization for model input and reconstruction
  # if you want to use PCA, set it to "pca_scaled"
  in_type: "scaled" # "pca_scaled"
  out_type: "scaled" # "pca_scaled"
  # number of pricipal components to use for PCA
  # n_pc: 50

  # set smaller batch_size (e.g., 256) for dataset
  #     1. with fewer cells to improve convergence speed;
  #     2. with more cells but low-end GPU to avoid "out of GPU memory error";
  # set larger batch_size (e.g., 1024, 4096) for dataset with more cells on high-end GPU to improve GPU utilization;
  batch_size: 1024

  # use pytorch ddp to support multi-gpu training
  use_ddp: True
  seed: null
